Shader "Unlit/Hologram"
{
	// Here, you declare properties that appear in the inspector for this shader.
	Properties
	{
		_MainTex("Albedo Texture", 2D) = "white" {}

	// This adds a color property to the inspector with a default value of 1,1,1,1 (white)
	_TintColor("Tint Color", Color) = (1,1,1,1)

		// Adds a transparency property to the inspector. Range is a variable type which is like a float that is automatically clamped between two values. Represented in inspector as a slider bar.
		// This is because an alpha value that is too high can cause visual glitches.
		_Transparency("Transparency", Range(0.0, 1)) = 0.25
		_CutoutThresh("Cutout Threshold", Range(0.0, 1.0)) = 0.2
		_VertexJitterX("Vertex Jitter X", Float) = 0.01
		_VertexJitterY("Vertex Jitter Y", Float) = 0.01
		_VertexJitterZ("Vertex Jitter Z", Float) = 0.01
	}

		// You can have multiple sub shaders for different builds (different platforms, etc.)
		SubShader
	{
		// Because we set the render type to transparent, we also had to add a 'queue' tag and set it to transparent. The queue defines the order in which things are rendered.
		// Transparent objects have to be rendered later because they need to show the pixels below them. Other tags (in order) are 'background', 'geometry', 'alpha test', 'transparent', overlay.
		Tags{ "Queue" = "Transparent" "RenderType" = "Transparent" }
		LOD 100

		// This tells us 'not to render to the depth buffer.' Not sure what that means, but transparent shaders need to have this turned off.
		ZWrite Off

		// This tells us how to blend transparent pixels with the colors of the pixels beneath them.
		Blend SrcAlpha OneMinusSrcAlpha

		// Pass is a bit like Update (I think?) but it goes through each pixel rendering a this material. (I think?)
		Pass
	{
		// Everything between here and 'ENDCG' is a block of code that is run on the GPU.
		CGPROGRAM

		// Defining the names that we'll use to call shaders later in this code.
		// IE, we'll use the word 'vert' to call the vertex shader.
#pragma vertex vert
#pragma fragment frag

		// Shaderlab doesn't use inheritance, so rather than inheriting functionality (like from Monobehavior), we have to include another file into this one at compile time.
		// 'UnityCG.cginc' includes a bunch of functionality that we'll use here.
#include "UnityCG.cginc"

		// A struct is a lot like a class. A way to group multiple variables into one memory block.
		// 'appdata' must take inputs given by Unity to be used in the shader? Handled by UnityCG.cginc?
		struct appdata
	{
		// A float4 is a 'packed array'. Functionally, it's an array that contains 4 floats (x, y, z, and w coordinates)
		// 'POSITION' is a 'semantic binding'. It tells our shader how this variable is going to be used in our rendering.
		// Does this tell Unity to take the POSITION data from each vertex and store it in this array that we just declared?
		float4 vertex : POSITION;

		// UV coordinates.
		float2 uv : TEXCOORD0;
	};

	// This struct will be filled in and returned by the 'vert' function below.
	struct v2f
	{
		float2 uv : TEXCOORD0;

		// SV_POSITION is like POSITION, but in screen space (clip space) rather than object space.
		float4 vertex : SV_POSITION;
	};

	// These turn our inspector properties from above into variables which can be used by the CG program.
	sampler2D _MainTex;
	float4 _MainTex_ST;
	float4 _TintColor;
	float _Transparency;
	float _CutoutThresh;
	float _VertexJitterX;
	float _VertexJitterY;
	float _VertexJitterZ;

	// This takes the shape of the model (its vertices) and potentially modifies it.
	// (Converts from object space to 'clip space' (space relative to the camera.)
	// Note that we're passing our appdata into this function. You could pass in the variables included in appdata seperately, just like in c#.
	v2f vert(appdata v)
	{
		// We declare a variable which will be returned at the end of this function, then passed into the 'frag' function below.
		v2f o;

		// Modify the vertex before translating it to screen space.
		// _Time.y is the same as Time.time in C#.
		v.vertex.x += _VertexJitterX;
		v.vertex.y += _VertexJitterY;
		v.vertex.z += _VertexJitterZ;

		// UnityObjectToClipPos() translates a vertex from object to clip space.
		o.vertex = UnityObjectToClipPos(v.vertex);

		// TRANFORM_TEX applies the texture to the model using uv coordinates. _MainTex includes tiling and offset data, which will also be used here.
		o.uv = TRANSFORM_TEX(v.uv, _MainTex);

		return o;
	}

	// This applies color to the shape that was output by the vert function. (At pixel level.)
	// We pass in the v2f struct generated by the vert function.
	// 'SV_Target' is a 'render target'. In this case, it's the frame buffer for the screen. So this data is given directly to the frame buffer.
	fixed4 frag(v2f i) : SV_Target
	{
		// Sample the texture
		// fixed4 is another type of packed array. (fixed represents Fixed-point numbers vs floating-point numbers. math stuff involving the location of decimal points I guess.)
		// Here, we're using a fixed4 to represent a color (r, g, b, a). You could use it for anything, though.
		// tex2D reads the colors from _MainTex, and the uvs from the vertex data to give the color to be rendered at a specific screen point.
		// We also add the tint color set in the inspector to color generated from the texture & uv.
		fixed4 col = tex2D(_MainTex, i.uv) + _TintColor;

	// Apply transparency value set in inspector.
	col.a = _Transparency;

	// clip() is used to discard pixel data that meets certain conditions. Here we are discarding pixels that have less than a certain amount of red.
	// We could also have written this as: if (col.r < _CutoutThresh) discard;
	// Discarded pixels are just not rendered. They're invisible.
	clip(col.r - _CutoutThresh);

	return col;
	}

		ENDCG
	}
	}
}
